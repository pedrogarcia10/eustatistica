{
  "hash": "c797e8ec3000e3b875aecf3a0a0a7ccd",
  "result": {
    "markdown": "---\ntitle: \"Trabalho de Confiabilidade\"\nauthor: \"Pedro Garcia\"\nlang: pt-br\nformat:\n  revealjs:\n    chalkboard: true\n    incremental: true\n    theme: dark\n    slide-number: true\n    hyml-math-method: katex\n    center: true\n    fig-align: center\n    logo: logo.png\n    css: styles.css\n    code-fold: true\n    toc: false\n    toc-depth: 3\n    code-summary: \"Mostre o Código\"\neditor: source\ninstitute: UFU\ndate: \"\"\ndate-format: DD-MM-YY\n---\n\n\n# Apresentação {.smaller background-image=\"fundo.jpg\" background-opacity=0.3 .justify}\n\n## Introdução {.smaller background-image=\"fundo.jpg\" background-opacity=0.3 .justify}\n\nNo futebol, especificamente no Brasil impera o `imediatismo` dos times em relação ao trabalho das comissões técnicas. Logo, ao decorrer de um único ano de competição muitos times acabando interrompendo o ciclo de trabalho, trocando de técnico mais de uma vez. E alguns dos fatores são : \n\n- Recentes resultados ruins\n- Instatisfação da torcida\n- Estagnação do time\n- Ausência de conquistas\n- Mudanças na diretoria e presidência\n\n## {.smaller background-image=\"fundo.jpg\" background-opacity=0.3 .justify}\n\nSendo assim, o objetivo desse trabaho é usar conceitos de confiabilidade para identificar quais variáveis tem impacto e qual a magnitude desse impacto. Utilizando algumas variáveis de estresse relacionadas ao desempenho e perfil dos times e treinador. Os dados foram capturados do site `Transfermarket`, contendo o histórico desde 2000 de treinadores dos 20 times atuais da série A do campeonato brasileiro, e também do Santos que está na série B.\n\n## Objetivos {.smaller background-image=\"fundo.jpg\" background-opacity=0.3 .justify}\n\n- Comparar adequação dos modelos `Weibull e exponencial`\n- Encontrar variável(is) que `impacta significativamente` e qual a sua `magnitude`\n- Interpretar mMedidas de confiabilidade` para o modelo proposto\n- Sugerir `melhorias`\n\n# Metodologia {.smaller background-image=\"fundo.jpg\" background-opacity=0.3 .justify}\n\n## Carregando Pacotes e Tratando Dados {.smaller background-image=\"fundo.jpg\" background-opacity=0.3 .justify}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrequire(stringr)\nlibrary(readxl)\nrequire(tidyr)\nrequire(dplyr)\nrequire(survival)\nrequire(zoo)\nrequire(lmtest)\n\nsetwd(\"c:/Users/pedro/Desktop/UFU/ULTIMO SEMESTRE 2024-1/CONFIABILIDADE\")\n\ndados = data.frame(read_xlsx(\"TEC.xlsx\",sheet = \"Tabela1\"))\n\n\ndados = dados[dados$Jogos >= 9,]\n\ndf = data.frame(); for(i in unique(dados$Tecnico)){\n  subset= arrange(dados[dados$Tecnico == i,],Desde)\n  subset$jogos_exp = lag(cumsum(subset$Jogos))\n  subset$PPJ_exp = lag(cumsum(subset$PPJ))\n  subset$clubes = 0:(nrow(subset)-1)\n  subset$PPJ_GER = subset$PPJ_exp/subset$clubes\n  subset$JOGOS_GER = subset$jogos_exp/subset$clubes\n  df = rbind(df,subset)\n}\n\ndados = df\n\ndados$tempos = dados$Jogos\ndados$cens = ifelse(is.na(dados$Mes_Fim),0,1)\n\ndados = dados[,which(colnames(dados) %in% c('Tecnico','Time','Idade','JOGOS_GER','PPJ_GER','tempos','cens','Ano_Inicio'))]\n```\n:::\n\n\n## Mostrando Dados {.smaller background-image=\"fundo.jpg\" background-opacity=0.3 .justify}\n\nNeste trabalho serão utilizadas as seguintes variáveis : `Técnico` (nome do treinador), `Time` (equipe do período de trabalho do treinador), `Ano_Inicio` (ano em que o treinador ingressou na equipe), `Idade` (idade do treinador no momento da contratação), `Jogos_Ger` (média de jogos disputados em equipes passadas), `PPJ_Ger` (média de pontos ganhos por jogo em trabalhos anteriores), `PPJ` (média de pontos quando saiu da equipe atual), `tempos` (número de jogos até a saída do treinador) e `cens` (são identificadas como censura se o treinador ainda está na equipe atualmente).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndados[sample(1:nrow(dados),size = 15),]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                   Tecnico Time Idade Ano_Inicio  PPJ_GER JOGOS_GER tempos cens\n573              Léo Condé  GOI    38       2016       NA        NA     16    1\n200        Alexandre Gallo  SAN    37       2005       NA        NA     34    1\n71           Paulo Autuori  CAP    64       2020 1.336000  37.20000     27    1\n351     Paulo César Gusmão  AGO    48       2011 1.256667  32.00000     10    1\n556    Luiz Fernando Iubel  CUI    34       2024       NA        NA     10    0\n268            Caio Júnior  FLA    43       2008 1.530000  38.00000     38    1\n126         Eduardo Coudet  CAM    48       2023 1.850000  46.00000     35    1\n275           Joel Santana  BAH    62       2011 1.706667  28.66667     18    1\n69           Paulo Autuori  CAP    59       2016 1.236667  34.66667     59    1\n103 Paulo César Carpegiani  VIT    69       2018 1.571429  22.00000     14    1\n164       Marcelo Oliveira  VAS    57       2012 1.300000  48.00000     10    1\n292        Fernando Lázaro SCCP    41       2022       NA        NA     17    1\n100 Paulo César Carpegiani  VIT    63       2012 1.547500  20.25000     33    1\n503          Sérgio Soares  BAH    48       2015 1.640000  11.00000     38    1\n566        Julinho Camargo  GOI    44       2015       NA        NA     17    1\n```\n:::\n:::\n\n\n## Seleção de Variáveis {.smaller background-image=\"fundo.jpg\" background-opacity=0.3 .justify}\n\nEm alguns testes realizados utilizando `seleção de variáveis` verificando a significância da contribuição de cada uma delas para os modelos Weibull e Exponencial, verifica-se que as métricas que mais contribuiram para o modelo foram `PPJ_Ger` e `PPJ`. Sendo assim, foi criada uma nova variável que é a combinação linear entre elas, onde o PPJ e PPJ_Ger tem 80% e 20%, respectivamente da contribuição final dessa variável, que será a única a ser incluída no modelo, junto com os tempos e as censuras.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndados$PPJ_CL = dados$PPJ*0.8+dados$PPJ_GER*0.2\n\nVARS = which(colnames(dados) %in% c('tempos','cens','PPJ_CL'))\ndados = dados[complete.cases(dados[,VARS]),]\n```\n:::\n\n\n## Ajuste dos Modelos {.smaller background-image=\"fundo.jpg\" background-opacity=0.3 .justify}\n\nWeibull\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\najust2<-survreg(Surv(tempos,cens)~., dist='weibull',data = dados[,VARS])\nsummary(ajust2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nsurvreg(formula = Surv(tempos, cens) ~ ., data = dados[, VARS], \n    dist = \"weibull\")\n              Value Std. Error     z      p\n(Intercept)  2.8483     0.2654 10.73 <2e-16\nPPJ_CL       0.4700     0.1729  2.72 0.0066\nLog(scale)  -0.2967     0.0335 -8.86 <2e-16\n\nScale= 0.743 \n\nWeibull distribution\nLoglik(model)= -1738.7   Loglik(intercept only)= -1742.5\n\tChisq= 7.51 on 1 degrees of freedom, p= 0.0061 \nNumber of Newton-Raphson Iterations: 5 \nn= 410 \n```\n:::\n:::\n\n\n## {.smaller background-image=\"fundo.jpg\" background-opacity=0.3 .justify}\n\nExponencial\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\najust1<-survreg(Surv(tempos,cens)~., dist='exponential',data = dados[,VARS])\nsummary(ajust1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nsurvreg(formula = Surv(tempos, cens) ~ ., data = dados[, VARS], \n    dist = \"exponential\")\n            Value Std. Error    z       p\n(Intercept) 2.679      0.355 7.55 4.2e-14\nPPJ_CL      0.523      0.232 2.26   0.024\n\nScale fixed at 1 \n\nExponential distribution\nLoglik(model)= -1770.3   Loglik(intercept only)= -1772.9\n\tChisq= 5.14 on 1 degrees of freedom, p= 0.023 \nNumber of Newton-Raphson Iterations: 4 \nn= 410 \n```\n:::\n:::\n\n\n\n## Likelihood Ratio Test {.smaller background-image=\"fundo.jpg\" background-opacity=0.3 .justify}\n\n## {.smaller background-image=\"fundo.jpg\" background-opacity=0.3 .justify}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlmtest::lrtest(ajust2) #weibull melhor\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLikelihood ratio test\n\nModel 1: Surv(tempos, cens) ~ PPJ_CL\nModel 2: Surv(tempos, cens) ~ 1\n  #Df  LogLik Df  Chisq Pr(>Chisq)   \n1   3 -1738.7                        \n2   2 -1742.5 -1 7.5104   0.006134 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nlmtest::lrtest(ajust1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLikelihood ratio test\n\nModel 1: Surv(tempos, cens) ~ PPJ_CL\nModel 2: Surv(tempos, cens) ~ 1\n  #Df  LogLik Df  Chisq Pr(>Chisq)  \n1   2 -1770.3                       \n2   1 -1772.9 -1 5.1415    0.02336 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nA partir dos p valores do TRV, `rejeitamos H0 nas distribuições a um nível de significância de 5%`, tendo indício de que os modelos complexos são mais adequados que os simples. Para decidir qual modelo escolher, osberva-se a magnitude do TRV, `onde o weibull foi o mais satisfatório`, alcancando cerca de 7.51 unidades na estatística.\n\n## Avaliação Gráfica {.smaller background-image=\"fundo.jpg\" background-opacity=0.3 .justify}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nattach(dados)\n\n\nx = dados$PPJ_CL\nres1 = exp( log(tempos)-coef(ajust1)[1]-coef(ajust1)[2]*x )\nres2 = exp( (log(tempos)-coef(ajust2)[1]-coef(ajust2)[2]*x )/ ajust2$scale )\n\nekm1<-survfit(Surv(res1,cens)~1)\nekm2<-survfit(Surv(res2,cens)~1)\ntime1<-ekm1$time\ntime2<-ekm2$time \n\nR.kp1<-ekm1$surv\nR.kp2<-ekm2$surv\n\nR.exp<- exp(-time1/1) # Se o modelo exp for adequado entaos os residuos devem ter dist. exponencial(1)\nR.Weib <- exp(-(time2/1)) # Se o modelo weibull for adequado entaos os residuos devem ter dist. weibull(1,1)\n\n\n\npar(mfrow=c(1,2))\nplot(R.kp1, R.exp, pch=16, ylim=range(c(0.0,1)), xlim=range(c(0,1)), xlab = \"R(t): Kaplan-Meier\",\n     ylab=\"S(t): exponencial\")\nlines(c(0,1), c(0,1), type=\"l\", lty=1)\nplot(R.kp2, R.Weib, pch=16, ylim=range(c(0.0,1)), xlim=range(c(0,1)), xlab = \"R(t): Kaplan-Meier\",\n     ylab=\"S(t): Weibull\")\nlines(c(0,1), c(0,1), type=\"l\", lty=1)\n```\n\n::: {.cell-output-display}\n![](APR_TRB_CONF_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## {.smaller background-image=\"fundo.jpg\" background-opacity=0.3 .justify}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npar(mfrow=c(1,2))\nplot(time1, -log(R.kp1), pch=16, xlab=\"tempos\", ylab=\"-log(R(t))\")\nplot(log(time2), log(-log(R.kp2)), pch=16, xlab=\"log(tempos)\", ylab=\"log(-log(R(t)))\")\n```\n\n::: {.cell-output-display}\n![](APR_TRB_CONF_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\nAnalisando os gráficos de R(t) vs S(t) e o de Linearização, percebe-se que o modelo Weibull é mais adequado.\n\n## Simulações e Medidas {.smaller background-image=\"fundo.jpg\" background-opacity=0.3 .justify}\n\nSerão realizadas simulações considerando `situações de técnicos que tiveram desempenho ruim, mediano e bom`, tanto no time atual (ppj_atual) quanto no time anterior (ppj_anterior), onde vamos combinar essas situações, de modo que o técnico pode ter uma passagem ruim no time anterior e agora ele está bem, uma passagem anterior e atual medianas e entre outras situações. Para o desempenho ruim, mediano e bom os pontos por jogo (ppj) serão dados por 1.1, 1.4 e 1.8, respectivamente. Logo, a partir de todas combinações possíveis formadas poderemos estimar medidas como `MTTF, tempo mediano, confiabilidade até o tempo t e intervalo de confiança`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nppj_atual = c(rep(1.8,3),rep(1.4,3),rep(1.1,3))\nppj_anterior = c(1.8,1.4,1.1,1.8,1.4,1.1,1.8,1.4,1.1)\nppj_cl = (ppj_atual*0.8)+(ppj_anterior*0.2)\n\nMTTF = c(); tp = c(); t = c(); Rt = c(); LS = c(); LI = c()\nfor(i in 1:length(ppj_cl)){\n  grau = ppj_cl[i]\n  p =0.5\n  MTTF[i] = exp(coef(ajust2)[1]+coef(ajust2)[2]*grau)*gamma(1+ajust2$scale)\n  tp[i] = exp(coef(ajust2)[1]+coef(ajust2)[2]*grau)*(-log(1-p))^(ajust2$scale)\n  t[i] = 19\n  Rt[i] = round(exp(-(t/(exp(coef(ajust2)[1]+coef(ajust2)[2]*grau)))^(ajust2$scale)),4)*100\n  LS[i] = exp(log(exp(coef(ajust2)[1]+coef(ajust2)[2]*grau))+1.96*sqrt(vcov(ajust2)[1,1]+((grau^2)*vcov(ajust2)[2,2])+(2*grau*vcov(ajust2)[1,2])))\n  LI[i] = exp(log(exp(coef(ajust2)[1]+coef(ajust2)[2]*grau))-1.96*sqrt(vcov(ajust2)[1,1]+((grau^2)*vcov(ajust2)[2,2])+(2*grau*vcov(ajust2)[1,2])))\n}\n```\n:::\n\n\n## {.smaller background-image=\"fundo.jpg\" background-opacity=0.3 .justify}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nround(data.frame(ppj_atual,ppj_anterior,MTTF,tp,t,Rt,LS,LI),1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  ppj_atual ppj_anterior MTTF   tp  t   Rt   LS   LI\n1       1.8          1.8 36.9 30.6 19 56.4 45.5 35.6\n2       1.8          1.4 35.5 29.5 19 55.5 42.9 34.9\n3       1.8          1.1 34.6 28.7 19 54.8 41.2 34.4\n4       1.4          1.8 31.7 26.3 19 52.7 37.4 32.0\n5       1.4          1.4 30.6 25.4 19 51.8 36.3 30.6\n6       1.4          1.1 29.7 24.7 19 51.0 35.7 29.4\n7       1.1          1.8 28.4 23.5 19 49.8 34.9 27.4\n8       1.1          1.4 27.3 22.7 19 48.9 34.4 25.8\n9       1.1          1.1 26.6 22.0 19 48.1 34.0 24.6\n```\n:::\n:::\n\n\nPela tabela, pode-se observar algumas situações bem interessantes. `A primeira é que quando o treinador vem de uma passagem boa por um clube e, ele mantém as expectativas no time atual, o tempo mediano dele nesse clube é de aproximadamente 31 jogos`, o tempo médio sem falhas é de cerca de 37 jogos, e o número de treinadores restantes após 19 jogo sé de aproximadamente 56.4%, e por fim é quase certo que o número de jogos desse tipo de treinador oscila em um intervalo de aproximadamente 36 a 46 jogos.\n\nQuando comparado com um outro extremo onde temos um `treinador que vem de um trabalho anterior bom e atualmente mal, o MTTF é de 28.4`, tempo mediano de 23.5, diminuindo cerca de 7 jogos em relação ao exemplo de técnico anterior, além disso o intervalo passa a ser de 27 a 35 jogos.\n\n\n\n## {.smaller background-image=\"fundo.jpg\" background-opacity=0.3 .justify}\n\nUm técnico que tem tempo considerado `mediano tanto no trabalho atual quanto no anterior, é quase certo que permaneça entre 30.5 e 36.3` não sendo tão diferente das demais combinações, com uma leve exceção para a primeira onde o técnico foi bem nos dois cenários.\n\nQuando comparado os intervalos de confiança dos diferentes cenários, `pode-se notar que o cenário onde o técnico foi bem em ambos os contextos tem intervalo que se difere apenas dos 3 últimos apresentados na tabela`, onde o técnico obteve desempenho atual ruim em todos os cenários, e variando no anterior.\n\nEvidenciando que em comparação com as demais combinações restantes, não há diferença 'significativa', mostrando que o número de jogos do comando técnico entre esses cenários não são diferentes. Logo a `longevidade pode ser considerada semelhante se o técnico tem um desempenho atual mediano e bom, e um anterior bom, mediano ou ruim`.\n\n\n## Conclusão {.smaller background-image=\"fundo.jpg\" background-opacity=0.3 .justify}\n\nEm resumo o modelo escolhido foi bem satisfatório nas análises gráficas, no Likelihood Ratio Test e na seleção da variável preditora, permitindo o uso desse modelo para estimar diferentes contextos de técnicos, buscando obter estimativas de confiabilidade, `entendendo o impacto que a performance tem na longevidade`.\n\n\n## Melhorias {.smaller background-image=\"fundo.jpg\" background-opacity=0.3 .justify}\n\n- `Buscar e criar` mais variáveis\n- `Testar` essas novas variáveis no modelo\n- Coletar `mais dados` de times da segunda divisão\n- Pegar dados de `competições europeias para comparação`\n\n## Referências {.smaller background-image=\"fundo.jpg\" background-opacity=0.3 .justify}\n\n-  [Transfermarket](https://www.transfermarkt.com.br/)\n-  [Gestão estratégica e confiabilidade](https://www.amazon.com.br/Estrat%C3%A9gica-Confiabilidade-Ricardo-Barusso-Lafraia/dp/8573037326)",
    "supporting": [
      "APR_TRB_CONF_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}